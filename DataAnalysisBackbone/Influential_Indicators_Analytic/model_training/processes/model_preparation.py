# -*- coding: utf-8 -*-
"""model_preparation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ynQ7wJcUTicB81WbHfCkoxRRKjlNkCSV
"""

import duckdb
import os
import glob
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV
import json
import datetime
import pickle

def execute_model_preparation():

    dirname = os.path.dirname(__file__)

    # load data
    con = duckdb.connect(database=os.path.join(dirname, '../../feature_generation/storage/datasets.duckdb'),read_only=True)
    train_features = con.execute("SELECT * FROM train_features").df()
    train_labels = con.execute("SELECT * FROM train_labels").df()
    train_labels = train_labels["medals"]  # Transform target into a Series object
    con.close()

    # modeling
    param_grid = {
        'bootstrap': [True],
        'max_depth': [5, 15, 25, 50],
        'n_estimators': [200, 500, 1000]
    }
    ## Create a based model
    model = RandomForestRegressor()
    ## Instantiate the grid search model
    grid_search = GridSearchCV(estimator=model, param_grid=param_grid,
                               cv=3, n_jobs=-1, verbose=2)

    grid_search.fit(train_features, train_labels)
    model = grid_search.best_estimator_
    # Save model

    ## metadata
    ts = datetime.datetime.now()
    model_metadata = dict()
    model_metadata["type"] = str(type(model).__name__)
    model_metadata["params"] = grid_search.best_params_
    model_metadata["train_size"] = train_features.shape
    model_metadata["features"] = list(train_features.columns)
    model_metadata["timestamp"] = int(ts.timestamp())
    ## save model and metadata
    os.mkdir(os.path.join(dirname, f'../storage/models/{model_metadata["type"]}_{model_metadata["timestamp"]}'))
    ### save the model to disk
    filename = os.path.join(dirname, f'../storage/models/{model_metadata["type"]}_{model_metadata["timestamp"]}/model.sav')
    pickle.dump(model, open(filename, 'wb'))
    ### save metadata of model aswell
    with open(os.path.join(dirname, f'../storage/models/{model_metadata["type"]}_{model_metadata["timestamp"]}/metadata.json'),
            'w') as fp:
        json.dump(model_metadata, fp)