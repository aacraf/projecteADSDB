# -*- coding: utf-8 -*-
"""dataIntegration.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aLkeEvxrkqrJ4zkwDtpAKrz8nC7uWwxg

# EXPLOTATION ZONE

1. Load data
2. Integrate data
3. Perform concrete data quality

## 1. Load data from trusted zone
"""

#!pip install duckdb

import duckdb
import pandas as pd
import os

# from google.colab import drive
# drive.mount('/content/drive')

# con = duckdb.connect(database='/content/drive/MyDrive/projecteADSDB/explotation/explotation.duckdb', read_only=False)

# df_governance = pd.read_sql("SELECT * FROM Governance_Data", con)
# df_olympics = pd.read_sql("SELECT * FROM Olympics_Data", con)
# df_countrylevel = pd.read_sql("SELECT * FROM Country_Level_Data", con)

# df_governance.head()

# df_olympics.head()

# df_countrylevel.head()

# """## 2.2. Integrate with data governance

# ## 2.2.2. integrate dataframes
# """

# data = pd.merge(df_countrylevel, df_governance, left_on=['year', 'iso'], right_on=['year', 'Country Code'])
# data.drop(columns=['Country Code'], inplace=True)

# data.drop(columns=['notes', 'population_%', 'GDP_%', 'land_area_%'])

# """# Store data"""

# con.execute("DROP TABLE IF EXISTS Governance_Data;")
# con.execute("DROP TABLE IF EXISTS Olympics_Data;")

# con.execute("DROP TABLE IF EXISTS Olympics_Data;")
# con.execute("CREATE TABLE IF NOT EXISTS Olympics_Data AS SELECT * FROM df_olympics")

# con.execute("DROP TABLE IF EXISTS Country_Data")
# con.execute("CREATE TABLE IF NOT EXISTS Country_Data AS SELECT * FROM data")

# con.execute("SHOW TABLES").fetchall()

# con.close()

# """# EXECUTION OF PROCESS"""

def execute_dataIntegration():

  dirname = os.path.dirname(__file__)

  # connect to explotation database
  con = duckdb.connect(database=os.path.join(pardir, 'explotation.duckdb'), read_only=False)

  # list all tables
  l = con.execute("SHOW TABLES").fetchall()
  out = list([t for (t,) in l])

  # close explotation database connection
  con.close()

  # indidf is the indicators dataframe
  indidf = pd.DataFrame()

  # we only integrate data about country indicators
  out.remove('Olympics_Data')

  # if there's at least one indicators table we get the first
  # otherwise we raise an exception
  if out:
    tablename = out[0]
    # we obtain the first indicators dataframe
    indidf = con.execute(f'SELECT * FROM {tablename}').df()
    # special case: if the indicators dataframe has no column with ISO name, we rename it 
    if 'Country Code' in indidf.columns:
      indidf.rename(columns={'Country Code': 'iso'}, inplace=True)
    # we remove the first indicators table name in order not the merge it twice
    out.remove(tablename)
  else:
    raise Exception("Sorry, no indicator tables found")

  dictdf = {}

  # store all the indicators dataframes (except the first one) into a dictionary
  for t in out:
    # obtain the dataframe and insert it into dictionary
    dictdf[t] = con.execute(f'SELECT * FROM {t}').df()
    # special case: if the indicators dataframe has no column with ISO name, we rename it 
    if 'Country Code' in dictdf[t].columns:
      dictdf[t].rename(columns={'Country Code': 'iso'}, inplace=True)

  # get year column name of the first indicator table
  year_col_indi = [col for col in indidf.columns if 'year' in col]
  year_col_indi = year_col_indi[0]
  # get iso/country column name of the first indicator table
  country_col_indi = [col for col in indidf.columns if 'iso' in col]
  country_col_indi = country_col_indi[0]

  # merge all the indicator dataframes 
  for newdf in dictdf:
    # get year column name of the indicator dataframe
    year_col_new = [col for col in dictdf[newdf].columns if 'year' in col]
    year_col_new = year_col_new[0]
    # get iso/country column name of the indicator dataframe
    country_col_new = [col for col in dictdf[newdf].columns if 'iso' in col]
    country_col_new = country_col_new[0]
    # merge the indicator dataframe with the result indicators dataframe
    indidf = pd.merge(indidf, dictdf[newdf], how='left', left_on=[year_col_indi, country_col_indi], right_on=[year_col_new, country_col_new])

  # drop irrelevant columns

  indidf.drop(columns=['notes', 'population_%', 'GDP_%', 'land_area_%'])

  # drop all indicators tables
  con.execute(f'DROP TABLE IF EXISTS {tablename};')

  for table in out:
    con.execute(f'DROP TABLE IF EXISTS {table};')

  # we create only one cuntry indicators table with all the dataframes merged together
  con.execute("CREATE TABLE IF NOT EXISTS Country_Data AS SELECT * FROM indidf")

  con.close()
